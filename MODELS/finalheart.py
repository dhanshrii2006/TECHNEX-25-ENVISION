# -*- coding: utf-8 -*-
"""finalheart.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i08j-yIBWr8Jb9vs06tP-eJvgVUB6y9V
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
!pip install tpot
from tpot import TPOTClassifier
import shap

data = pd.read_csv("heart_disease.csv")

print(data.head())

heart_data.tail()

heart_data.shape

print(data.info())

print(data.describe())

print(data.isnull().sum())

heart_data['target'].value_counts()

target_column = "target"  # Replace "target" with the actual name of your target column
X = data.drop(columns=[target_column])
y = data[target_column]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print(X.shape, X_train.shape, X_test.shape)

numerical_features = X.select_dtypes(include=["int64", "float64"]).columns
categorical_features = X.select_dtypes(include=["object", "category"]).columns

numeric_transformer = Pipeline(steps=[("scaler", StandardScaler())])
categorical_transformer = Pipeline(steps=[("encoder", OneHotEncoder(handle_unknown="ignore"))])

preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, numerical_features),
        ("cat", categorical_transformer, categorical_features),
    ]
)

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report, accuracy_score

pipeline = Pipeline(steps=[("preprocessor", preprocessor), ("classifier", RandomForestClassifier(random_state=42))])

param_grid = {
    "classifier__n_estimators": [100, 200, 300],
    "classifier__max_depth": [5, 10, None],
    "classifier__min_samples_split": [2, 5, 10],
}
grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring="accuracy", n_jobs=-1)

grid_search.fit(X_train, y_train)

print("Best Parameters:", grid_search.best_params_)
best_model = grid_search.best_estimator_

y_pred = best_model.predict(X_test)
print("Accuracy on Test Set:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

import shap

explainer = shap.Explainer(best_model.named_steps["classifier"], X_train)

shap_values = explainer(X_test)

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer


numeric_features = ["age", "chol", "trestbps"]
categorical_features = ["sex", "cp"]

numeric_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="mean")),
    ("scaler", StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("onehot", OneHotEncoder(handle_unknown="ignore"))
])

preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, numeric_features),
        ("cat", categorical_transformer, categorical_features)
    ]
)

X_train_transformed = preprocessor.fit_transform(X_train)
X_test_transformed = preprocessor.transform(X_test)

X_test_transformed = pd.DataFrame(
    X_test_transformed,
    columns=preprocessor.get_feature_names_out()
)


print(X_test_transformed.head())

import joblib

joblib.dump(best_model, "heart_disease_model.pkl")


loaded_model = joblib.load("heart_disease_model.pkl")

from tpot import TPOTClassifier

tpot = TPOTClassifier(generations=5, population_size=50, cv=5, random_state=42, verbosity=2)
tpot.fit(X_train, y_train)

tpot.export("tpot_heart_disease_pipeline.py")

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# Splitting the dataset
X = data.drop("target", axis=1)  # Features
y = data["target"]  # Target (0 = No Heart Attack, 1 = Heart Attack)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Preprocessing (e.g., ColumnTransformer pipeline, as shown earlier)
X_train_transformed = preprocessor.fit_transform(X_train)
X_test_transformed = preprocessor.transform(X_test)

# Train a Random Forest Classifier
model = RandomForestClassifier(random_state=42)
model.fit(X_train_transformed, y_train)

# Predict probabilities
y_pred_prob = model.predict_proba(X_test_transformed)[:, 1]  # Probability of having a heart attack

# Predict classes (0 = No Heart Attack, 1 = Heart Attack)
y_pred = model.predict(X_test_transformed)

# Add predictions to the test dataset
X_test["Heart_Attack_Probability"] = y_pred_prob
X_test["Heart_Attack_Prediction"] = y_pred

# Display the results
print(X_test[["Heart_Attack_Probability", "Heart_Attack_Prediction"]].head())

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Evaluate accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:\n", conf_matrix)

# Classification report
class_report = classification_report(y_test, y_pred)
print("Classification Report:\n", class_report)

heart_data['target'].value_counts()

print(X)

print(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=2)

print(X.shape, X_train.shape, X_test.shape)

model = LogisticRegression()

model.fit(X_train, y_train)

input_data = (57,1,2,150,168,0,174,0,1.6,2,0,2,1)

# change the input data to a numpy array
input_data_as_numpy_array= np.asarray(input_data)

# reshape the numpy array as we are predicting for only on instance
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction = model.predict(input_data_reshaped)
print(prediction)

if (prediction[0]== 0):
  print('The Person does not have a Heart Disease')
else:
  print('The Person has Heart Disease')













input_data = (62,0,0,140,268,0,0,160,0,3.6,0,2,2)

# change the input data to a numpy array
input_data_as_numpy_array= np.asarray(input_data)

# reshape the numpy array as we are predicting for only on instance
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction = model.predict(input_data_reshaped)
print(prediction)

if (prediction[0]== 0):
  print('The Person does not have a Heart Disease')
else:
  print('The Person has Heart Disease')



